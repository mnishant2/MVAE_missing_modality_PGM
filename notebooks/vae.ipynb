{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vae.ipynb","provenance":[],"collapsed_sections":["Erwo2ywMF-MR","mcs7QFvETxQJ","NTB40neeR6-k","HXp5vuhDTg1J","8Iz6QX_KTizK"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"59ef550e19ab4fdf9bcabce63bdebdb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3e37b5163f2d4ddb998ebb22c57169c5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4e987c3e9a344b35bceb3794472120dd","IPY_MODEL_5990d36f4a7a4fcab80a0f755cf78aca"]}},"3e37b5163f2d4ddb998ebb22c57169c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4e987c3e9a344b35bceb3794472120dd":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_93f3cc7e1887490081cacabe599261d8","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3bfed1f239b047db8e216b9348b5d628"}},"5990d36f4a7a4fcab80a0f755cf78aca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_75e83f91d0ea4a27810f4004d95b780d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 78405632/? [00:07&lt;00:00, 10329087.88it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fd04c92cf9f3416d883d4a0aa03433db"}},"93f3cc7e1887490081cacabe599261d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3bfed1f239b047db8e216b9348b5d628":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75e83f91d0ea4a27810f4004d95b780d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fd04c92cf9f3416d883d4a0aa03433db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"39b62d3ac53f4c0c96257347b31f16e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_32680a747abf4bac9c6d6f3b5a77bf29","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8b48253b099d44f1b1ae58dff925b681","IPY_MODEL_8f7dd556764c4c67ad2fff599f913c6d"]}},"32680a747abf4bac9c6d6f3b5a77bf29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b48253b099d44f1b1ae58dff925b681":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ec20dee32a04418ab272d821841ff41e","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09b6d83730154c1f87060d2be1581e78"}},"8f7dd556764c4c67ad2fff599f913c6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a0027173dccc44d895c0594911091f5b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 15687680/? [00:02&lt;00:00, 5476875.17it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d12b98ceba4b43bcb965bfcb0bdc0644"}},"ec20dee32a04418ab272d821841ff41e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"09b6d83730154c1f87060d2be1581e78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a0027173dccc44d895c0594911091f5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d12b98ceba4b43bcb965bfcb0bdc0644":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a184fd7123c94d799f564731cd6e9435":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_022774e613254179acb404428567aa41","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4e060a60164641fcbfba7cd2ea6cc6d7","IPY_MODEL_b4152314e7464288b7b185f4b193dc28"]}},"022774e613254179acb404428567aa41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4e060a60164641fcbfba7cd2ea6cc6d7":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6c935116b92744ca9c540ff0cff77f9c","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_67d928f1c92f4ca3b810056917f52fdd"}},"b4152314e7464288b7b185f4b193dc28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6ceab970ea9a4bed91b2c4a0a7e88144","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 15687680/? [00:02&lt;00:00, 6025419.91it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b31eceb9a1e4ec69bb4166536ccbbdf"}},"6c935116b92744ca9c540ff0cff77f9c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"67d928f1c92f4ca3b810056917f52fdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ceab970ea9a4bed91b2c4a0a7e88144":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1b31eceb9a1e4ec69bb4166536ccbbdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Erwo2ywMF-MR"},"source":["### Instructions"]},{"cell_type":"markdown","metadata":{"id":"qC71Qv1-TtI-"},"source":["\n","Solution template for the question 1.6-1.7. This template consists of following steps. Except the step 2, you don't need to modify it to answer the questions.\n","1.   Initialize libraries\n","2.   **Insert the answers for the questions 1.1~1.5 below (this is the part you need to fill)**\n","3.   Define data loaders\n","4.   Define VAE network architecture\n","5.   Initialize the model and optimizer\n","6.   Train the model\n","7.   Save the model\n","8.   Load the model\n","9.   Evaluate the model with importance sampling"]},{"cell_type":"markdown","metadata":{"id":"mcs7QFvETxQJ"},"source":["### Initialize libraries\n"]},{"cell_type":"code","metadata":{"id":"uLoP5GRpEPbI"},"source":["import math\n","from torchvision.datasets import utils\n","import torch.utils.data as data_utils\n","import torch\n","import os\n","import numpy as np\n","from torch import nn\n","from torch.nn.modules import upsampling\n","from torch.functional import F\n","from torch.optim import Adam"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NTB40neeR6-k"},"source":["### Insert **the answers for the questions 1.1~1.5 below**"]},{"cell_type":"code","metadata":{"id":"0Kr08AArNlHU"},"source":["\"\"\"\n","Template for Question 1 of hwk3.\n","@author: Shawn Tan and Jae Hyun Lim\n","\"\"\"\n","import math\n","import numpy as np\n","import torch\n","\n","\n","def log_likelihood_bernoulli(mu, target):\n","    \"\"\" \n","    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n","    *** note. ***\n","    :param mu: (FloatTensor) - shape: (batch_size x input_size) - The mean of Bernoulli random variables p(x=1).\n","    :param target: (FloatTensor) - shape: (batch_size x input_size) - Target samples (binary values).\n","    :return: (FloatTensor) - shape: (batch_size,) - log-likelihood of target samples on the Bernoulli random variables.\n","    \"\"\"\n","    # init\n","    batch_size = mu.size(0)\n","    mu = mu.view(batch_size, -1)\n","    target = target.view(batch_size, -1)\n","\n","    # log_likelihood_bernoulli\n","    log_likelihood = torch.sum(target*torch.log(mu) + (1-target)*torch.log(1-mu), -1)\n","    # print(log_likelihood)\n","    return log_likelihood\n","\n","\n","def log_likelihood_normal(mu, logvar, z):\n","    \"\"\" \n","    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n","    *** note. ***\n","    :param mu: (FloatTensor) - shape: (batch_size x input_size) - The mean of Normal distributions.\n","    :param logvar: (FloatTensor) - shape: (batch_size x input_size) - The log variance of Normal distributions.\n","    :param z: (FloatTensor) - shape: (batch_size x input_size) - Target samples.\n","    :return: (FloatTensor) - shape: (batch_size,) - log probability of the sames on the given Normal distributions.\n","    \"\"\"\n","    # init\n","    batch_size = mu.size(0)\n","    mu = mu.view(batch_size, -1)\n","    logvar = logvar.view(batch_size, -1)\n","    z = z.view(batch_size, -1)\n","\n","    # log normal\n","    log_likelihood = torch.sum(-0.5 * (np.log(2 * np.pi) + logvar) + (z - mu)**2 * (-0.5 * 1/(torch.exp(logvar))), -1)\n","    return log_likelihood\n","\n","\n","def log_mean_exp(y):\n","    \"\"\" \n","    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n","    *** note. ***\n","    :param y: (FloatTensor) - shape: (batch_size x sample_size) - Values to be evaluated for log_mean_exp. For example log proababilies\n","    :return: (FloatTensor) - shape: (batch_size,) - Output for log_mean_exp.\n","    \"\"\"\n","    # init\n","    batch_size = y.size(0)\n","    sample_size = y.size(1)\n","\n","    # log_mean_exp\n","    maximum = torch.max(y, -1, keepdim=True)[0]\n","    y_log_mean_exp = torch.log(torch.mean(torch.exp(y - maximum), -1, keepdim=True))\n","    output = (y_log_mean_exp + maximum).squeeze()\n","    return output\n","\n","\n","def kl_gaussian_gaussian_analytic(mu_q, logvar_q, mu_p, logvar_p):\n","    \"\"\" \n","    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n","    *** note. ***\n","    :param mu_q: (FloatTensor) - shape: (batch_size x input_size) - The mean of first distributions (Normal distributions).\n","    :param logvar_q: (FloatTensor) - shape: (batch_size x input_size) - The log variance of first distributions (Normal distributions).\n","    :param mu_p: (FloatTensor) - shape: (batch_size x input_size) - The mean of second distributions (Normal distributions).\n","    :param logvar_p: (FloatTensor) - shape: (batch_size x input_size) - The log variance of second distributions (Normal distributions).\n","    :return: (FloatTensor) - shape: (batch_size,) - kl-divergence of KL(q||p).\n","    \"\"\"\n","    # init\n","    batch_size = mu_q.size(0)\n","    mu_q = mu_q.view(batch_size, -1)\n","    logvar_q = logvar_q.view(batch_size, -1)\n","    mu_p = mu_p.view(batch_size, -1)\n","    logvar_p = logvar_p.view(batch_size, -1)\n","\n","    t1 = logvar_p - logvar_q - 1\n","    t2 = ((mu_q - mu_p)**2 + torch.exp(logvar_q))/torch.exp(logvar_p)\n","    output = torch.sum(0.5 * (t1 + t2), -1)\n","\n","    # kld\n","    return output\n","\n","\n","def kl_gaussian_gaussian_mc(mu_q, logvar_q, mu_p, logvar_p, num_samples=1):\n","    \"\"\" \n","    COMPLETE ME. DONT MODIFY THE PARAMETERS OF THE FUNCTION. Otherwise, tests might fail.\n","    *** note. ***\n","    :param mu_q: (FloatTensor) - shape: (batch_size x input_size) - The mean of first distributions (Normal distributions).\n","    :param logvar_q: (FloatTensor) - shape: (batch_size x input_size) - The log variance of first distributions (Normal distributions).\n","    :param mu_p: (FloatTensor) - shape: (batch_size x input_size) - The mean of second distributions (Normal distributions).\n","    :param logvar_p: (FloatTensor) - shape: (batch_size x input_size) - The log variance of second distributions (Normal distributions).\n","    :param num_samples: (int) - shape: () - The number of sample for Monte Carlo estimate for KL-divergence\n","    :return: (FloatTensor) - shape: (batch_size,) - kl-divergence of KL(q||p).\n","    \"\"\"\n","    # init\n","    batch_size = mu_q.size(0)\n","    input_size = np.prod(mu_q.size()[1:])\n","    mu_q = mu_q.view(\n","        batch_size, -1).unsqueeze(1).expand(batch_size, num_samples, input_size)\n","    logvar_q = logvar_q.view(\n","        batch_size, -1).unsqueeze(1).expand(batch_size, num_samples, input_size)\n","    mu_p = mu_p.view(\n","        batch_size, -1).unsqueeze(1).expand(batch_size, num_samples, input_size)\n","    logvar_p = logvar_p.view(\n","        batch_size, -1).unsqueeze(1).expand(batch_size, num_samples, input_size)\n","\n","    t1 = logvar_p - logvar_q - 1\n","    t2 = ((mu_q - mu_p)**2 + torch.exp(logvar_q))/torch.exp(logvar_p)\n","    output = torch.sum(0.5 * (t1 + t2), -1)\n","\n","    # kld\n","    return torch.mean(output, -1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r3v_ld3ITRFl"},"source":["### Define data loaders"]},{"cell_type":"code","metadata":{"id":"oiK4L0TdETNb"},"source":["def get_data_loader(dataset_location, batch_size):\n","    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n","    # start processing\n","    def lines_to_np_array(lines):\n","        return np.array([[int(i) for i in line.split()] for line in lines])\n","    splitdata = []\n","    for splitname in [\"train\", \"valid\", \"test\"]:\n","        filename = \"binarized_mnist_%s.amat\" % splitname\n","        filepath = os.path.join(dataset_location, filename)\n","        utils.download_url(URL + filename, dataset_location)\n","        with open(filepath) as f:\n","            lines = f.readlines()\n","        x = lines_to_np_array(lines).astype('float32')\n","        x = x.reshape(x.shape[0], 1, 28, 28)\n","        # pytorch data loader\n","        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n","        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n","        splitdata.append(dataset_loader)\n","    return splitdata"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZsL1gLLEVJM","colab":{"base_uri":"https://localhost:8080/","height":235,"referenced_widgets":["59ef550e19ab4fdf9bcabce63bdebdb1","3e37b5163f2d4ddb998ebb22c57169c5","4e987c3e9a344b35bceb3794472120dd","5990d36f4a7a4fcab80a0f755cf78aca","93f3cc7e1887490081cacabe599261d8","3bfed1f239b047db8e216b9348b5d628","75e83f91d0ea4a27810f4004d95b780d","fd04c92cf9f3416d883d4a0aa03433db","39b62d3ac53f4c0c96257347b31f16e3","32680a747abf4bac9c6d6f3b5a77bf29","8b48253b099d44f1b1ae58dff925b681","8f7dd556764c4c67ad2fff599f913c6d","ec20dee32a04418ab272d821841ff41e","09b6d83730154c1f87060d2be1581e78","a0027173dccc44d895c0594911091f5b","d12b98ceba4b43bcb965bfcb0bdc0644","a184fd7123c94d799f564731cd6e9435","022774e613254179acb404428567aa41","4e060a60164641fcbfba7cd2ea6cc6d7","b4152314e7464288b7b185f4b193dc28","6c935116b92744ca9c540ff0cff77f9c","67d928f1c92f4ca3b810056917f52fdd","6ceab970ea9a4bed91b2c4a0a7e88144","1b31eceb9a1e4ec69bb4166536ccbbdf"]},"outputId":"bfe66d51-7409-4649-e48a-257fa103e15f"},"source":["train, valid, test = get_data_loader(\"binarized_mnist\", 64)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_train.amat to binarized_mnist/binarized_mnist_train.amat\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59ef550e19ab4fdf9bcabce63bdebdb1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_valid.amat to binarized_mnist/binarized_mnist_valid.amat\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39b62d3ac53f4c0c96257347b31f16e3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_test.amat to binarized_mnist/binarized_mnist_test.amat\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a184fd7123c94d799f564731cd6e9435","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8PoFxey7TUFS"},"source":["### Define VAE network architecture\n"]},{"cell_type":"code","metadata":{"id":"POBmU6UCEb4l"},"source":["class Encoder(nn.Module):\n","    def __init__(self, latent_size):\n","        super(Encoder, self).__init__()\n","        self.mlp = nn.Sequential(\n","            nn.Linear(784, 300),\n","            nn.ELU(),\n","            nn.Linear(300, 300),\n","            nn.ELU(),\n","            nn.Linear(300, 2 * latent_size),\n","        )\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        z_mean, z_logvar = self.mlp(x.view(batch_size, 784)).chunk(2, dim=-1)\n","        return z_mean, z_logvar\n","\n","class Decoder(nn.Module):\n","    def __init__(self, latent_size):\n","        super(Decoder, self).__init__()\n","        self.mlp = nn.Sequential(\n","            nn.Linear(latent_size, 300),\n","            nn.ELU(),\n","            nn.Linear(300, 300),\n","            nn.ELU(),\n","            nn.Linear(300, 784),\n","        )\n","        \n","    def forward(self, z):\n","        return self.mlp(z) - 5.\n","\n","class VAE(nn.Module):\n","    def __init__(self, latent_size):\n","        super(VAE, self).__init__()\n","        self.encode = Encoder(latent_size)\n","        self.decode = Decoder(latent_size)\n","\n","    def forward(self, x):\n","        z_mean, z_logvar = self.encode(x)\n","        z_sample = z_mean + torch.exp(z_logvar / 2.) * torch.randn_like(z_logvar)\n","        x_mean = self.decode(z_sample)\n","        return z_mean, z_logvar, x_mean\n","\n","    def loss(self, x, z_mean, z_logvar, x_mean):\n","        ZERO = torch.zeros(z_mean.size())\n","        #kl = kl_gaussian_gaussian_mc(z_mean, z_logvar, ZERO, ZERO, num_samples=1000).mean()\n","        kl = kl_gaussian_gaussian_analytic(z_mean, z_logvar, ZERO, ZERO).mean()\n","        recon_loss = -log_likelihood_bernoulli(\n","            torch.sigmoid(x_mean.view(x.size(0), -1)),\n","            x.view(x.size(0), -1),            \n","        ).mean()\n","        return recon_loss + kl"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Phg07ERvTYuh"},"source":["### Initialize a model and optimizer"]},{"cell_type":"code","metadata":{"id":"xTxgDwZfEesO","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"ee359e66-ef97-47b4-bbf6-7d17c1d59e3b"},"source":["vae = VAE(100)\n","params = vae.parameters()\n","optimizer = Adam(params, lr=3e-4)\n","print(vae)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["VAE(\n","  (encode): Encoder(\n","    (mlp): Sequential(\n","      (0): Linear(in_features=784, out_features=300, bias=True)\n","      (1): ELU(alpha=1.0)\n","      (2): Linear(in_features=300, out_features=300, bias=True)\n","      (3): ELU(alpha=1.0)\n","      (4): Linear(in_features=300, out_features=200, bias=True)\n","    )\n","  )\n","  (decode): Decoder(\n","    (mlp): Sequential(\n","      (0): Linear(in_features=100, out_features=300, bias=True)\n","      (1): ELU(alpha=1.0)\n","      (2): Linear(in_features=300, out_features=300, bias=True)\n","      (3): ELU(alpha=1.0)\n","      (4): Linear(in_features=300, out_features=784, bias=True)\n","    )\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Oqw9SI7aTdtG"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"SWtQakAOEhxN","colab":{"base_uri":"https://localhost:8080/","height":357},"outputId":"bc58c612-768c-464b-c287-b0a893657d15"},"source":["for i in range(20):\n","    # train\n","    for x in train:\n","        optimizer.zero_grad()\n","        z_mean, z_logvar, x_mean = vae(x)\n","        loss = vae.loss(x, z_mean, z_logvar, x_mean)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # evaluate ELBO on the valid dataset\n","    with torch.no_grad():\n","        total_loss = 0.\n","        total_count = 0\n","        for x in valid:\n","            total_loss += vae.loss(x, *vae(x)) * x.size(0)\n","            total_count += x.size(0)\n","        print('-elbo: ', (total_loss / total_count).item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-elbo:  164.27865600585938\n","-elbo:  139.9281463623047\n","-elbo:  127.03173828125\n","-elbo:  119.94197845458984\n","-elbo:  116.20686340332031\n","-elbo:  113.37294006347656\n","-elbo:  110.95308685302734\n","-elbo:  108.92073822021484\n","-elbo:  107.71062469482422\n","-elbo:  106.52680206298828\n","-elbo:  105.59500885009766\n","-elbo:  104.85894775390625\n","-elbo:  103.95008850097656\n","-elbo:  103.62915802001953\n","-elbo:  103.03475952148438\n","-elbo:  102.18987274169922\n","-elbo:  101.99149322509766\n","-elbo:  101.5129623413086\n","-elbo:  101.3018569946289\n","-elbo:  101.10104370117188\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HXp5vuhDTg1J"},"source":["### Save the model"]},{"cell_type":"code","metadata":{"id":"JYfmW5TAElEO","colab":{"base_uri":"https://localhost:8080/","height":139},"outputId":"3ee93a6c-9174-4596-d363-a16a19411801"},"source":["torch.save(vae, 'model.pt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type VAE. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"8Iz6QX_KTizK"},"source":["### Load the model"]},{"cell_type":"code","metadata":{"id":"Hqcb8BrmEnMh"},"source":["vae = torch.load('model.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OTpoVRncTmSR"},"source":["### Evaluate the $\\log p_\\theta(x)$ of the model on test by using importance sampling"]},{"cell_type":"code","metadata":{"id":"tc2q6dxgEsIh","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"341d8efa-6da8-44e6-f39e-eac3eaa9c9cb"},"source":["total_loss = 0.\n","total_count = 0\n","with torch.no_grad():\n","    #x = next(iter(test))\n","    for x in test:\n","        # init\n","        K = 200\n","        M = x.size(0)\n","\n","        # Sample from the posterior\n","        z_mean, z_logvar = vae.encode(x)\n","        eps = torch.randn(z_mean.size(0), K, z_mean.size(1))\n","        z_samples = z_mean[:, None, :] + torch.exp(z_logvar / 2.)[:, None, :] * eps # Broadcast the noise over the mean and variance\n","\n","        # Decode samples\n","        z_samples_flat = z_samples.view(-1, z_samples.size(-1)) # Flatten out the z samples\n","        x_mean_flat = vae.decode(z_samples_flat) # Push it through\n","\n","        # Reshape images and posterior to evaluate probabilities\n","        x_flat = x[:, None].repeat(1, K, 1, 1, 1).reshape(M*K, -1)\n","        z_mean_flat = z_mean[:, None, :].expand_as(z_samples).reshape(M*K, -1)\n","        z_logvar_flat =  z_logvar[:, None, :].expand_as(z_samples).reshape(M*K, -1)\n","        ZEROS = torch.zeros(z_mean_flat.size())\n","\n","        # Calculate all the probabilities!\n","        log_p_x_z = log_likelihood_bernoulli(torch.sigmoid(x_mean_flat), x_flat).view(M, K)\n","        log_q_z_x = log_likelihood_normal(z_mean_flat, z_logvar_flat, z_samples_flat).view(M, K)\n","        log_p_z = log_likelihood_normal(ZEROS, ZEROS, z_samples_flat).view(M, K)\n","\n","        # Recombine them.\n","        w = log_p_x_z + log_p_z - log_q_z_x\n","        log_p = log_mean_exp(w)\n","\n","        # Accumulate\n","        total_loss += log_p.sum()\n","        total_count += M\n","      \n","print('log p(x):', (total_loss / total_count).item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["log p(x): -95.35819244384766\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A-P2PbtDC_Zf"},"source":[""],"execution_count":null,"outputs":[]}]}